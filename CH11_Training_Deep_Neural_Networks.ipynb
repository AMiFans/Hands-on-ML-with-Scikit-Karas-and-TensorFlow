{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# TensorFlow ≥2.0-preview is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"deep\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanishing/Exploding Gradients Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure sigmoid_saturation_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = np.linspace(-5, 5, 200)\n",
    "\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [1, 1], 'k--')\n",
    "plt.plot([0, 0], [-0.2, 1.2], 'k-')\n",
    "plt.plot([-5, 5], [-3/4, 7/4], 'g--')\n",
    "plt.plot(z, logit(z), \"b-\", linewidth=2)\n",
    "props = dict(facecolor='black', shrink=0.1)\n",
    "plt.annotate('Saturating', xytext=(3.5, 0.7), xy=(5, 1), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.annotate('Saturating', xytext=(-3.5, 0.3), xy=(-5, 0), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.annotate('Linear', xytext=(2, 0.2), xy=(0, 0.5), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.grid(True)\n",
    "plt.title(\"Sigmoid activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.2, 1.2])\n",
    "\n",
    "save_fig(\"sigmoid_saturation_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xavier and He Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Constant',\n",
       " 'GlorotNormal',\n",
       " 'GlorotUniform',\n",
       " 'Identity',\n",
       " 'Initializer',\n",
       " 'Ones',\n",
       " 'Orthogonal',\n",
       " 'RandomNormal',\n",
       " 'RandomUniform',\n",
       " 'TruncatedNormal',\n",
       " 'VarianceScaling',\n",
       " 'Zeros',\n",
       " 'constant',\n",
       " 'deserialize',\n",
       " 'get',\n",
       " 'glorot_normal',\n",
       " 'glorot_uniform',\n",
       " 'he_normal',\n",
       " 'he_uniform',\n",
       " 'identity',\n",
       " 'lecun_normal',\n",
       " 'lecun_uniform',\n",
       " 'ones',\n",
       " 'orthogonal',\n",
       " 'serialize',\n",
       " 'zeros']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[name for name in dir(keras.initializers) if not name.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x7f8c20156860>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.Dense(10, activation=\"relu\", kernel_initializer=\"he_normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x7f8c311715c0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init = keras.initializers.VarianceScaling(scale=2., mode='fan_avg',\n",
    "                                          distribution='uniform')\n",
    "keras.layers.Dense(10, activation=\"relu\", kernel_initializer=init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonsaturating Activation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leaky ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaky_relu(z, alpha=0.01):\n",
    "    return np.maximum(alpha*z, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure leaky_relu_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(z, leaky_relu(z, 0.05), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([0, 0], [-0.5, 4.2], 'k-')\n",
    "plt.grid(True)\n",
    "props = dict(facecolor='black', shrink=0.1)\n",
    "plt.annotate('Leak', xytext=(-3.5, 0.5), xy=(-5, -0.2), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.title(\"Leaky ReLU activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.5, 4.2])\n",
    "\n",
    "save_fig(\"leaky_relu_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deserialize',\n",
       " 'elu',\n",
       " 'exponential',\n",
       " 'get',\n",
       " 'hard_sigmoid',\n",
       " 'linear',\n",
       " 'relu',\n",
       " 'selu',\n",
       " 'serialize',\n",
       " 'sigmoid',\n",
       " 'softmax',\n",
       " 'softplus',\n",
       " 'softsign',\n",
       " 'tanh']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m for m in dir(keras.activations) if not m.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LeakyReLU', 'PReLU', 'ReLU', 'ThresholdedReLU']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m for m in dir(keras.layers) if \"relu\" in m.lower()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train a neural network on Fashion MNIST using the Leaky ReLU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_train_full = X_train_full / 255.0\n",
    "X_test = X_test / 255.0\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 28, 28)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]), # flatten to (55000, 784)\n",
    "    keras.layers.Dense(300, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.LeakyReLU(),\n",
    "    keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.LeakyReLU(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 4s 65us/sample - loss: 1.2806 - accuracy: 0.6250 - val_loss: 0.8883 - val_accuracy: 0.7152\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 3s 54us/sample - loss: 0.7954 - accuracy: 0.7373 - val_loss: 0.7135 - val_accuracy: 0.7648\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 3s 51us/sample - loss: 0.6816 - accuracy: 0.7727 - val_loss: 0.6356 - val_accuracy: 0.7882\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 2s 44us/sample - loss: 0.6215 - accuracy: 0.7935 - val_loss: 0.5922 - val_accuracy: 0.8012\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 3s 49us/sample - loss: 0.5830 - accuracy: 0.8081 - val_loss: 0.5596 - val_accuracy: 0.8172\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 2s 43us/sample - loss: 0.5553 - accuracy: 0.8155 - val_loss: 0.5338 - val_accuracy: 0.8240\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 2s 43us/sample - loss: 0.5340 - accuracy: 0.8221 - val_loss: 0.5157 - val_accuracy: 0.8310\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 2s 43us/sample - loss: 0.5172 - accuracy: 0.8265 - val_loss: 0.5035 - val_accuracy: 0.8336\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 3s 49us/sample - loss: 0.5036 - accuracy: 0.8299 - val_loss: 0.4950 - val_accuracy: 0.8354\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 3s 47us/sample - loss: 0.4922 - accuracy: 0.8324 - val_loss: 0.4797 - val_accuracy: 0.8430\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try Parametric Rectified Linear Unit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.PReLU(),\n",
    "    keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.PReLU(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.PReLU(),\n",
    "    keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.PReLU(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 3s 57us/sample - loss: 1.3470 - accuracy: 0.6225 - val_loss: 0.9268 - val_accuracy: 0.7200\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 3s 49us/sample - loss: 0.8208 - accuracy: 0.7357 - val_loss: 0.7322 - val_accuracy: 0.7640\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 3s 48us/sample - loss: 0.6972 - accuracy: 0.7697 - val_loss: 0.6494 - val_accuracy: 0.7868\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 3s 50us/sample - loss: 0.6332 - accuracy: 0.7904 - val_loss: 0.6027 - val_accuracy: 0.8024\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 3s 47us/sample - loss: 0.5918 - accuracy: 0.8051 - val_loss: 0.5674 - val_accuracy: 0.8140\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 3s 48us/sample - loss: 0.5619 - accuracy: 0.8140 - val_loss: 0.5393 - val_accuracy: 0.8252\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 3s 52us/sample - loss: 0.5391 - accuracy: 0.8216 - val_loss: 0.5203 - val_accuracy: 0.8306\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 3s 50us/sample - loss: 0.5212 - accuracy: 0.8251 - val_loss: 0.5070 - val_accuracy: 0.8332\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 3s 52us/sample - loss: 0.5067 - accuracy: 0.8289 - val_loss: 0.4971 - val_accuracy: 0.8332\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 3s 54us/sample - loss: 0.4944 - accuracy: 0.8322 - val_loss: 0.4811 - val_accuracy: 0.8416\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "p_re_lu_2 (PReLU)            (None, 300)               300       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "p_re_lu_3 (PReLU)            (None, 100)               100       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 267,010\n",
      "Trainable params: 267,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# keras.utils.plot_model(model, \"my_mnist_model.png\", show_shapes=True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELU\n",
    "Let's play Exponential Linear Unit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elu(z, alpha=1):\n",
    "    return np.where(z < 0, alpha * (np.exp(z) - 1), z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure elu_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(z, elu(z), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [-1, -1], 'k--')\n",
    "plt.plot([0, 0], [-2.2, 3.2], 'k-')\n",
    "plt.grid(True)\n",
    "plt.title(r\"ELU activation function ($\\alpha=1$)\", fontsize=14)\n",
    "plt.axis([-5, 5, -2.2, 3.2])\n",
    "\n",
    "save_fig(\"elu_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing ELU in TensorFlow is trivial, just specify the activation function when building each layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x7f8c20186978>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.Dense(10, activation=\"elu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SELU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This activation function was proposed in this [great paper](https://arxiv.org/pdf/1706.02515.pdf) by Günter Klambauer, Thomas Unterthiner and Andreas Mayr, published in June 2017. During training, a neural network composed exclusively of a stack of __dense layers__ using the __SELU activation__ function and __LeCun initialization__ will __self-normalize__: \n",
    "\n",
    "### requirement: __standardized inputs, sequential model, dense layers, LeCun initialization__ \n",
    "\n",
    ">the output of each layer will tend to preserve the same mean and variance during training, \n",
    "\n",
    "which solves the vanishing/exploding gradients problem. As a result, this activation function outperforms the other activation functions very significantly for such neural nets, so you should really try it out. \n",
    "\n",
    "Unfortunately, the self-normalizing property of the SELU activation function is easily broken: you cannot use ℓ<sub>1</sub> or ℓ<sub>2</sub> regularization, regular dropout, max-norm, skip connections or other non-sequential topologies (so recurrent neural networks won't self-normalize). However, in practice it works quite well with sequential CNNs. If you break self-normalization, SELU will not necessarily outperform other activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import erfc\n",
    "\n",
    "# alpha and scale to self normalize with mean 0 and standard deviation 1\n",
    "# (see equation 14 in the paper):\n",
    "alpha_0_1 = -np.sqrt(2 / np.pi) / (erfc(1/np.sqrt(2)) * np.exp(1/2) - 1)\n",
    "scale_0_1 = (\n",
    "            (1 - erfc(1 / np.sqrt(2)) * np.sqrt(np.e)) \n",
    "            * np.sqrt(2 * np.pi) * (2 * erfc(np.sqrt(2))*np.e**2  \n",
    "            + np.pi*erfc(1/np.sqrt(2))**2*np.e \n",
    "            - 2*(2+np.pi)*erfc(1/np.sqrt(2))*np.sqrt(np.e)+np.pi+2)**(-1/2)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selu(z, scale=scale_0_1, alpha=alpha_0_1):\n",
    "    return scale * elu(z, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure selu_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(z, selu(z), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [-1.758, -1.758], 'k--')\n",
    "plt.plot([0, 0], [-2.2, 3.2], 'k-')\n",
    "plt.grid(True)\n",
    "plt.title(\"SELU activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -2.2, 3.2])\n",
    "\n",
    "save_fig(\"selu_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the SELU hyperparameters (`scale` and `alpha`) are tuned in such a way that the mean output of each neuron remains close to 0, and the standard deviation remains close to 1 (assuming the inputs are standardized with mean 0 and standard deviation 1 too). Using this activation function, even a 1,000 layer deep neural network preserves roughly mean 0 and standard deviation 1 across all layers, avoiding the exploding/vanishing gradients problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0: mean -0.00, std deviation 1.00\n",
      "Layer 100: mean 0.02, std deviation 0.96\n",
      "Layer 200: mean 0.01, std deviation 0.90\n",
      "Layer 300: mean -0.02, std deviation 0.92\n",
      "Layer 400: mean 0.05, std deviation 0.89\n",
      "Layer 500: mean 0.01, std deviation 0.93\n",
      "Layer 600: mean 0.02, std deviation 0.92\n",
      "Layer 700: mean -0.02, std deviation 0.90\n",
      "Layer 800: mean 0.05, std deviation 0.83\n",
      "Layer 900: mean 0.02, std deviation 1.00\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "Z = np.random.normal(size=(500, 100)) # standardized inputs\n",
    "for layer in range(1000):\n",
    "    W = np.random.normal(size=(100, 100), scale=np.sqrt(1 / 100)) # LeCun initialization\n",
    "    Z = selu(Z@W)\n",
    "    means = np.mean(Z, axis=0).mean()\n",
    "    stds = np.std(Z, axis=0).mean()\n",
    "    if layer % 100 == 0:\n",
    "        print(\"Layer {}: mean {:.2f}, std deviation {:.2f}\".format(layer, means, stds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using SELU is easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x7f8c70ebb5c0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.Dense(10, activation=\"selu\",\n",
    "                   kernel_initializer=\"lecun_normal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a neural net for Fashion MNIST with 100 hidden layers, using the SELU activation function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py:4268: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation=\"selu\",\n",
    "                             kernel_initializer=\"lecun_normal\"))\n",
    "for layer in range(99):\n",
    "    model.add(keras.layers.Dense(100, activation=\"selu\",\n",
    "                                 kernel_initializer=\"lecun_normal\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train it. Do not forget to scale the inputs to mean 0 and standard deviation 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 28, 28)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't forget keepdims\n",
    "pixel_means = X_train.mean(axis=0, keepdims=True)\n",
    "pixel_stds = X_train.std(axis=0, keepdims=True)\n",
    "X_train_scaled = (X_train - pixel_means) / pixel_stds\n",
    "X_valid_scaled = (X_valid - pixel_means) / pixel_stds\n",
    "X_test_scaled = (X_test - pixel_means) / pixel_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "55000/55000 [==============================] - 33s 605us/sample - loss: 1.3654 - accuracy: 0.4650 - val_loss: 1.3350 - val_accuracy: 0.4226\n",
      "Epoch 2/5\n",
      "55000/55000 [==============================] - 41s 742us/sample - loss: 1.0764 - accuracy: 0.5620 - val_loss: 0.8297 - val_accuracy: 0.6720\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - 29s 528us/sample - loss: 0.7583 - accuracy: 0.7122 - val_loss: 0.6718 - val_accuracy: 0.7572\n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - 30s 540us/sample - loss: 0.6541 - accuracy: 0.7585 - val_loss: 0.6227 - val_accuracy: 0.7784\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - 31s 556us/sample - loss: 0.6078 - accuracy: 0.7786 - val_loss: 0.5928 - val_accuracy: 0.7966\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, y_train, epochs=5,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now look at what happens if we try to use the ReLU activation function instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\", # now \"ReLu\"\n",
    "                             kernel_initializer=\"he_normal\"))\n",
    "for layer in range(99):\n",
    "    model.add(keras.layers.Dense(100, activation=\"relu\", \n",
    "                                 kernel_initializer=\"he_normal\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "55000/55000 [==============================] - 18s 327us/sample - loss: 1.8183 - accuracy: 0.2622 - val_loss: 1.2275 - val_accuracy: 0.4776\n",
      "Epoch 2/5\n",
      "55000/55000 [==============================] - 15s 266us/sample - loss: 1.1048 - accuracy: 0.5380 - val_loss: 0.9821 - val_accuracy: 0.5538\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - 17s 312us/sample - loss: 0.9367 - accuracy: 0.6199 - val_loss: 0.8287 - val_accuracy: 0.6860\n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - 20s 368us/sample - loss: 0.7906 - accuracy: 0.6868 - val_loss: 0.7166 - val_accuracy: 0.7484\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - 16s 298us/sample - loss: 0.6905 - accuracy: 0.7417 - val_loss: 0.6236 - val_accuracy: 0.7564\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, y_train, epochs=5,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "[selu] \n",
    "Epoch 5/5\n",
    "55000/55000 [==============================] - 52s 943us/sample - loss: 0.6078 - accuracy: 0.7786 - val_loss: 0.5928 - val_accuracy: 0.7966\n",
    "[relu]\n",
    "55000/55000 [==============================] - 30s 542us/sample - loss: 0.6905 - accuracy: 0.7417 - val_loss: 0.6236 - val_accuracy: 0.7564\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not great at all, we suffered from the vanishing/exploding gradients problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although using He initialization along with ELU (or any variant of ReLU) can significantly reduce the vanishing/exploding gradients problems at the beginning of training, it doesn’t guarantee that they won’t come back during training.\n",
    "\n",
    "`Batch Normalization (BN)` consists of adding an operation in the model just before or after the activation function of each hidden layer, simply zero-centering and normalizing each input, then scaling and shifting the result using two new parameter vectors per layer: one for scaling, the other for shifting. In other words, this operation lets the model learn the optimal scale and mean of each of the layer’s inputs. In many cases, if you add a BN layer as the very first layer of your neural network, you do not need to standardize your training set.\n",
    "\n",
    "`Note`: 1 unit in the previous layer requires 4 parameters for batch normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    \n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    \n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    \n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_5 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense_215 (Dense)            (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_216 (Dense)            (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_217 (Dense)            (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 271,346\n",
      "Trainable params: 268,978\n",
      "Non-trainable params: 2,368\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('batch_normalization/gamma:0', True),\n",
       " ('batch_normalization/beta:0', True),\n",
       " ('batch_normalization/moving_mean:0', False),\n",
       " ('batch_normalization/moving_variance:0', False)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn1 = model.layers[1]\n",
    "[(var.name, var.trainable) for var in bn1.variables]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gamma is the output scale parameter vector for the layer and beta is the output shift (offset) parameter vector for the layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'cond/Identity' type=Identity>,\n",
       " <tf.Operation 'cond_1/Identity' type=Identity>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn1.updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 5s 99us/sample - loss: 0.8767 - accuracy: 0.7137 - val_loss: 0.5532 - val_accuracy: 0.8208\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 4s 79us/sample - loss: 0.5755 - accuracy: 0.8018 - val_loss: 0.4759 - val_accuracy: 0.8458\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 4s 75us/sample - loss: 0.5154 - accuracy: 0.8212 - val_loss: 0.4395 - val_accuracy: 0.8542\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 4s 77us/sample - loss: 0.4842 - accuracy: 0.8312 - val_loss: 0.4161 - val_accuracy: 0.8594\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 4s 75us/sample - loss: 0.4561 - accuracy: 0.8424 - val_loss: 0.4003 - val_accuracy: 0.8644\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 4s 75us/sample - loss: 0.4400 - accuracy: 0.8468 - val_loss: 0.3884 - val_accuracy: 0.8702\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 4s 75us/sample - loss: 0.4245 - accuracy: 0.8508 - val_loss: 0.3795 - val_accuracy: 0.8722\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 4s 74us/sample - loss: 0.4114 - accuracy: 0.8563 - val_loss: 0.3735 - val_accuracy: 0.8714\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 4s 73us/sample - loss: 0.4030 - accuracy: 0.8585 - val_loss: 0.3665 - val_accuracy: 0.8762\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 4s 70us/sample - loss: 0.3955 - accuracy: 0.8601 - val_loss: 0.3596 - val_accuracy: 0.8764\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes applying BN before the activation function works better (there's a debate on this topic). Moreover, the layer before a `BatchNormalization` layer __does not need to have bias terms__, since the `BatchNormalization` layer some as well, it would be a waste of parameters, so you can set `use_bias=False` when creating those layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, use_bias=False), \n",
    "    keras.layers.BatchNormalization(), # now notice that it's before activation function\n",
    "    keras.layers.Activation(\"relu\"),\n",
    "    keras.layers.Dense(100, use_bias=False),\n",
    "    keras.layers.Activation(\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_6 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense_218 (Dense)            (None, 300)               235200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_219 (Dense)            (None, 100)               30000     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_220 (Dense)            (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 270,946\n",
      "Trainable params: 268,578\n",
      "Non-trainable params: 2,368\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 5s 85us/sample - loss: 0.8632 - accuracy: 0.7101 - val_loss: 0.5635 - val_accuracy: 0.8104\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 4s 70us/sample - loss: 0.5795 - accuracy: 0.8012 - val_loss: 0.4848 - val_accuracy: 0.8374\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 4s 70us/sample - loss: 0.5188 - accuracy: 0.8217 - val_loss: 0.4480 - val_accuracy: 0.8470\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 4s 68us/sample - loss: 0.4832 - accuracy: 0.8309 - val_loss: 0.4253 - val_accuracy: 0.8550\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 4s 68us/sample - loss: 0.4588 - accuracy: 0.8399 - val_loss: 0.4093 - val_accuracy: 0.8602\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 4s 80us/sample - loss: 0.4398 - accuracy: 0.8475 - val_loss: 0.3983 - val_accuracy: 0.8628\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 5s 87us/sample - loss: 0.4249 - accuracy: 0.8508 - val_loss: 0.3900 - val_accuracy: 0.8686\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 4s 80us/sample - loss: 0.4133 - accuracy: 0.8545 - val_loss: 0.3839 - val_accuracy: 0.8684\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 5s 89us/sample - loss: 0.4029 - accuracy: 0.8578 - val_loss: 0.3746 - val_accuracy: 0.8682\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 5s 84us/sample - loss: 0.3952 - accuracy: 0.8604 - val_loss: 0.3710 - val_accuracy: 0.8702\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0891242e-18, 6.4668331e-15, 1.4509570e-19, 7.4868200e-15,\n",
       "        1.4285656e-19, 9.9861872e-01, 5.8086532e-22, 6.5719208e-10,\n",
       "        1.6701212e-15, 1.3812929e-03],\n",
       "       [1.6223912e-13, 4.2282824e-14, 1.0000000e+00, 4.7137431e-14,\n",
       "        5.2299765e-09, 5.3410325e-11, 1.4546795e-09, 3.6435177e-15,\n",
       "        1.7946608e-15, 2.1117806e-12],\n",
       "       [1.1400070e-16, 1.0000000e+00, 2.8676460e-19, 1.9894204e-15,\n",
       "        1.8474077e-14, 1.2614805e-12, 4.9713220e-18, 6.9929146e-21,\n",
       "        2.4329714e-17, 1.6451126e-18],\n",
       "       [7.7966198e-18, 1.0000000e+00, 5.6248251e-19, 3.0500550e-12,\n",
       "        1.0615453e-17, 4.7535760e-11, 5.3458026e-22, 1.1114442e-21,\n",
       "        2.1668764e-19, 2.3247770e-15],\n",
       "       [7.0678572e-05, 1.0373458e-09, 5.7475955e-07, 3.0852661e-05,\n",
       "        1.7740500e-06, 2.4537288e-04, 9.9965024e-01, 7.7310008e-10,\n",
       "        2.3520850e-11, 4.1947251e-07]], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test_scaled[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0891200e-18, 6.4668081e-15, 1.4509460e-19, 7.4868200e-15,\n",
       "        1.4285602e-19, 9.9861872e-01, 5.8086088e-22, 6.5718958e-10,\n",
       "        1.6701148e-15, 1.3812771e-03],\n",
       "       [1.6223943e-13, 4.2282906e-14, 1.0000000e+00, 4.7137611e-14,\n",
       "        5.2299960e-09, 5.3410731e-11, 1.4546850e-09, 3.6435457e-15,\n",
       "        1.7946676e-15, 2.1117847e-12],\n",
       "       [1.1400113e-16, 1.0000000e+00, 2.8676679e-19, 1.9894280e-15,\n",
       "        1.8474182e-14, 1.2614878e-12, 4.9713030e-18, 6.9929413e-21,\n",
       "        2.4329809e-17, 1.6451189e-18],\n",
       "       [7.7966198e-18, 1.0000000e+00, 5.6248251e-19, 3.0500491e-12,\n",
       "        1.0615412e-17, 4.7535760e-11, 5.3457622e-22, 1.1114399e-21,\n",
       "        2.1668764e-19, 2.3247592e-15],\n",
       "       [7.0678703e-05, 1.0373458e-09, 5.7476120e-07, 3.0852632e-05,\n",
       "        1.7740500e-06, 2.4537335e-04, 9.9965024e-01, 7.7310303e-10,\n",
       "        2.3520895e-11, 4.1947371e-07]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test_scaled[:5], batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isclose(model.predict(X_test_scaled[:5]), \n",
    "           model.predict(X_test_scaled[:5], batch_size=1)).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Clipping\n",
    "\n",
    "All Keras optimizers accept `clipnorm` or `clipvalue` arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(clipvalue=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will clip every component of the gradient vector to a value between –1.0 and 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(clipnorm=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to ensure that `Gradient Clipping` does not change the direction of the gradient vector, you should clip by `norm` by setting `clipnorm` instead of `clipvalue`. This will clip the whole gradient if its $\\ell_2$ norm is greater than the threshold you picked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reusing Pretrained Layers\n",
    "It is generally not a good idea to train a very large DNN from scratch: instead, you should always try to find an existing neural network that accomplishes a similar task to the one you are trying to tackle then just reuse the lower layers of this network: this is called `transfer learning`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reusing a Keras model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the fashion MNIST training set in two:\n",
    "* `X_train_A`: all images of all items except for sandals and shirts (classes 5 and 6).\n",
    "* `X_train_B`: a much smaller training set of just the first 200 images of sandals or shirts.\n",
    "\n",
    "The validation set and the test set are also split this way, but without restricting the number of images.\n",
    "\n",
    "We will __train a model on set A (classification task with 8 classes), and try to reuse it to tackle set B (binary classification)__. We hope to transfer a little bit of knowledge from task A to task B, since classes in set A (sneakers, ankle boots, coats, t-shirts, etc.) are somewhat similar to classes in set B (sandals and shirts). However, since we are using `Dense` layers, only patterns that occur at the same location can be reused (in contrast, convolutional layers will transfer much better, since learned patterns can be detected anywhere on the image, as we will see in the CNN chapter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(X, y):\n",
    "    y_5_or_6 = (y == 5) | (y == 6) # sandals or shirts\n",
    "    y_A = y[~y_5_or_6]\n",
    "    y_A[y_A > 6] -= 2 # class indices 7, 8, 9 should be moved to 5, 6, 7\n",
    "    y_B = (y[y_5_or_6] == 6).astype(np.float32) # binary classification task: is it a shirt (class 6)?\n",
    "    return ((X[~y_5_or_6], y_A),\n",
    "            (X[y_5_or_6], y_B))\n",
    "\n",
    "(X_train_A, y_train_A), (X_train_B, y_train_B) = split_dataset(X_train, y_train)\n",
    "(X_valid_A, y_valid_A), (X_valid_B, y_valid_B) = split_dataset(X_valid, y_valid)\n",
    "(X_test_A, y_test_A), (X_test_B, y_test_B) = split_dataset(X_test, y_test)\n",
    "X_train_B = X_train_B[:200]\n",
    "y_train_B = y_train_B[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43986, 28, 28)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 28, 28)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 5, 7, 7, 7, 4, 4, 3, 4, 0, 1, 6, 3, 4, 3, 2, 6, 5, 3, 4, 5,\n",
       "       1, 3, 4, 2, 0, 6, 7, 1], dtype=uint8)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_A[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7], dtype=uint8)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_B[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = keras.models.Sequential()\n",
    "model_A.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_A.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
    "model_A.add(keras.layers.Dense(8, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 43986 samples, validate on 4014 samples\n",
      "Epoch 1/20\n",
      "43986/43986 [==============================] - 4s 91us/sample - loss: 0.5909 - accuracy: 0.8100 - val_loss: 0.3772 - val_accuracy: 0.8712\n",
      "Epoch 2/20\n",
      "43986/43986 [==============================] - 3s 76us/sample - loss: 0.3520 - accuracy: 0.8793 - val_loss: 0.3393 - val_accuracy: 0.8782\n",
      "Epoch 3/20\n",
      "43986/43986 [==============================] - 3s 75us/sample - loss: 0.3167 - accuracy: 0.8889 - val_loss: 0.3016 - val_accuracy: 0.8961\n",
      "Epoch 4/20\n",
      "43986/43986 [==============================] - 3s 74us/sample - loss: 0.2969 - accuracy: 0.8967 - val_loss: 0.2858 - val_accuracy: 0.9031\n",
      "Epoch 5/20\n",
      "43986/43986 [==============================] - 3s 74us/sample - loss: 0.2824 - accuracy: 0.9032 - val_loss: 0.2807 - val_accuracy: 0.9063\n",
      "Epoch 6/20\n",
      "43986/43986 [==============================] - 3s 77us/sample - loss: 0.2721 - accuracy: 0.9071 - val_loss: 0.2683 - val_accuracy: 0.9103\n",
      "Epoch 7/20\n",
      "43986/43986 [==============================] - 3s 76us/sample - loss: 0.2642 - accuracy: 0.9097 - val_loss: 0.2680 - val_accuracy: 0.9111\n",
      "Epoch 8/20\n",
      "43986/43986 [==============================] - 3s 74us/sample - loss: 0.2570 - accuracy: 0.9119 - val_loss: 0.2738 - val_accuracy: 0.9046\n",
      "Epoch 9/20\n",
      "43986/43986 [==============================] - 3s 75us/sample - loss: 0.2513 - accuracy: 0.9141 - val_loss: 0.2587 - val_accuracy: 0.9116\n",
      "Epoch 10/20\n",
      "43986/43986 [==============================] - 3s 72us/sample - loss: 0.2456 - accuracy: 0.9162 - val_loss: 0.2595 - val_accuracy: 0.9108\n",
      "Epoch 11/20\n",
      "43986/43986 [==============================] - 3s 74us/sample - loss: 0.2416 - accuracy: 0.9180 - val_loss: 0.2487 - val_accuracy: 0.9158\n",
      "Epoch 12/20\n",
      "43986/43986 [==============================] - 4s 83us/sample - loss: 0.2378 - accuracy: 0.9187 - val_loss: 0.2449 - val_accuracy: 0.9163\n",
      "Epoch 13/20\n",
      "43986/43986 [==============================] - 4s 99us/sample - loss: 0.2342 - accuracy: 0.9205 - val_loss: 0.2451 - val_accuracy: 0.9155\n",
      "Epoch 14/20\n",
      "43986/43986 [==============================] - 5s 104us/sample - loss: 0.2307 - accuracy: 0.9209 - val_loss: 0.2437 - val_accuracy: 0.9158\n",
      "Epoch 15/20\n",
      "43986/43986 [==============================] - 5s 122us/sample - loss: 0.2278 - accuracy: 0.9218 - val_loss: 0.2393 - val_accuracy: 0.9190\n",
      "Epoch 16/20\n",
      "43986/43986 [==============================] - 6s 146us/sample - loss: 0.2249 - accuracy: 0.9226 - val_loss: 0.2392 - val_accuracy: 0.9183\n",
      "Epoch 17/20\n",
      "43986/43986 [==============================] - 8s 183us/sample - loss: 0.2218 - accuracy: 0.9236 - val_loss: 0.2388 - val_accuracy: 0.9183\n",
      "Epoch 18/20\n",
      "43986/43986 [==============================] - 9s 209us/sample - loss: 0.2198 - accuracy: 0.9243 - val_loss: 0.2400 - val_accuracy: 0.9178\n",
      "Epoch 19/20\n",
      "43986/43986 [==============================] - 9s 215us/sample - loss: 0.2176 - accuracy: 0.9252 - val_loss: 0.2330 - val_accuracy: 0.9208\n",
      "Epoch 20/20\n",
      "43986/43986 [==============================] - 10s 216us/sample - loss: 0.2153 - accuracy: 0.9255 - val_loss: 0.2326 - val_accuracy: 0.9200\n"
     ]
    }
   ],
   "source": [
    "history = model_A.fit(X_train_A, y_train_A, epochs=20,\n",
    "                    validation_data=(X_valid_A, y_valid_A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras model on this set and got reasonably good performance (>90% accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A.save(\"my_model_A.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train on (X_train_B, y_train_B) without transfer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same architecture as model A\n",
    "model_B = keras.models.Sequential()\n",
    "model_B.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_B.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
    "model_B.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 200 samples, validate on 986 samples\n",
      "Epoch 1/20\n",
      "200/200 [==============================] - 2s 10ms/sample - loss: 0.9545 - accuracy: 0.4600 - val_loss: 0.6655 - val_accuracy: 0.5385\n",
      "Epoch 2/20\n",
      "200/200 [==============================] - 0s 839us/sample - loss: 0.5899 - accuracy: 0.6900 - val_loss: 0.4785 - val_accuracy: 0.8519\n",
      "Epoch 3/20\n",
      "200/200 [==============================] - 0s 856us/sample - loss: 0.4512 - accuracy: 0.8800 - val_loss: 0.4098 - val_accuracy: 0.8945\n",
      "Epoch 4/20\n",
      "200/200 [==============================] - 0s 853us/sample - loss: 0.3871 - accuracy: 0.9100 - val_loss: 0.3666 - val_accuracy: 0.9128\n",
      "Epoch 5/20\n",
      "200/200 [==============================] - 0s 857us/sample - loss: 0.3438 - accuracy: 0.9250 - val_loss: 0.3315 - val_accuracy: 0.9300\n",
      "Epoch 6/20\n",
      "200/200 [==============================] - 0s 848us/sample - loss: 0.3095 - accuracy: 0.9300 - val_loss: 0.3034 - val_accuracy: 0.9402\n",
      "Epoch 7/20\n",
      "200/200 [==============================] - 0s 876us/sample - loss: 0.2810 - accuracy: 0.9400 - val_loss: 0.2808 - val_accuracy: 0.9432\n",
      "Epoch 8/20\n",
      "200/200 [==============================] - 0s 893us/sample - loss: 0.2580 - accuracy: 0.9500 - val_loss: 0.2618 - val_accuracy: 0.9462\n",
      "Epoch 9/20\n",
      "200/200 [==============================] - 0s 868us/sample - loss: 0.2372 - accuracy: 0.9600 - val_loss: 0.2447 - val_accuracy: 0.9513\n",
      "Epoch 10/20\n",
      "200/200 [==============================] - 0s 862us/sample - loss: 0.2196 - accuracy: 0.9650 - val_loss: 0.2316 - val_accuracy: 0.9513\n",
      "Epoch 11/20\n",
      "200/200 [==============================] - 0s 840us/sample - loss: 0.2048 - accuracy: 0.9650 - val_loss: 0.2182 - val_accuracy: 0.9533\n",
      "Epoch 12/20\n",
      "200/200 [==============================] - 0s 841us/sample - loss: 0.1915 - accuracy: 0.9650 - val_loss: 0.2071 - val_accuracy: 0.9564\n",
      "Epoch 13/20\n",
      "200/200 [==============================] - 0s 831us/sample - loss: 0.1791 - accuracy: 0.9650 - val_loss: 0.1959 - val_accuracy: 0.9594\n",
      "Epoch 14/20\n",
      "200/200 [==============================] - 0s 923us/sample - loss: 0.1681 - accuracy: 0.9700 - val_loss: 0.1864 - val_accuracy: 0.9604\n",
      "Epoch 15/20\n",
      "200/200 [==============================] - 0s 900us/sample - loss: 0.1579 - accuracy: 0.9850 - val_loss: 0.1778 - val_accuracy: 0.9625\n",
      "Epoch 16/20\n",
      "200/200 [==============================] - 0s 852us/sample - loss: 0.1491 - accuracy: 0.9850 - val_loss: 0.1695 - val_accuracy: 0.9675\n",
      "Epoch 17/20\n",
      "200/200 [==============================] - 0s 848us/sample - loss: 0.1411 - accuracy: 0.9900 - val_loss: 0.1626 - val_accuracy: 0.9686\n",
      "Epoch 18/20\n",
      "200/200 [==============================] - 0s 829us/sample - loss: 0.1339 - accuracy: 0.9900 - val_loss: 0.1570 - val_accuracy: 0.9686\n",
      "Epoch 19/20\n",
      "200/200 [==============================] - 0s 838us/sample - loss: 0.1277 - accuracy: 0.9900 - val_loss: 0.1522 - val_accuracy: 0.9696\n",
      "Epoch 20/20\n",
      "200/200 [==============================] - 0s 865us/sample - loss: 0.1217 - accuracy: 0.9900 - val_loss: 0.1471 - val_accuracy: 0.9696\n"
     ]
    }
   ],
   "source": [
    "history = model_B.fit(X_train_B, y_train_B, epochs=20,\n",
    "                      validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the same architecture as model A, it performs reasonably well (97% accuracy), but since it’s a much easier task (there are just 2 classes), you were hoping for more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![figure11-4](https://github.com/soo-pecialist/Hands_on_ML_w_Scikit_Karas_and_TensorFlow/blob/master/images_used/figure11_4.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = keras.models.load_model(\"my_model_A.h5\")\n",
    "# drop softmax (output) layer\n",
    "model_B_on_A = keras.models.Sequential(model_A.layers[:-1]) \n",
    "# instead, add sigmoid activation.\n",
    "model_B_on_A.add(keras.layers.Dense(1, activation=\"sigmoid\")) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `model_A` and `model_B_on_A` now share some layers. When you train `model_B_on_A`, it will also __affect__ `model_A`. If you want to avoid that, you need to __clone__ `model_A` before you reuse its layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A_clone = keras.models.clone_model(model_A)\n",
    "model_A_clone.set_weights(model_A.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Freeze the reused layers during the first few epochs, giving the new output layer some time to learn reasonable weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 200 samples, validate on 986 samples\n",
      "Epoch 1/4\n",
      "200/200 [==============================] - 2s 10ms/sample - loss: 0.5807 - accuracy: 0.6550 - val_loss: 0.5813 - val_accuracy: 0.6450\n",
      "Epoch 2/4\n",
      "200/200 [==============================] - 0s 754us/sample - loss: 0.5425 - accuracy: 0.7050 - val_loss: 0.5468 - val_accuracy: 0.6815\n",
      "Epoch 3/4\n",
      "200/200 [==============================] - 0s 783us/sample - loss: 0.5086 - accuracy: 0.7200 - val_loss: 0.5164 - val_accuracy: 0.7140\n",
      "Epoch 4/4\n",
      "200/200 [==============================] - 0s 805us/sample - loss: 0.4784 - accuracy: 0.7600 - val_loss: 0.4870 - val_accuracy: 0.7292\n"
     ]
    }
   ],
   "source": [
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = False # freeze weights in these layers\n",
    "\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\",\n",
    "                     optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                     metrics=[\"accuracy\"])\n",
    "\n",
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=4,\n",
    "                           validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `Note`: You must always compile your model after you freeze or unfreeze layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, unfreeze the reused layers (which requires compiling the model again) and continue training to fine-tune the reused layers for task B. After unfreezing the reused layers, it is usually a good idea to reduce the learning rate, once again to avoid damaging the reused weights. However, in this example, we do not alter the learning rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 200 samples, validate on 986 samples\n",
      "Epoch 1/16\n",
      "200/200 [==============================] - 2s 8ms/sample - loss: 0.3964 - accuracy: 0.8200 - val_loss: 0.3384 - val_accuracy: 0.8722\n",
      "Epoch 2/16\n",
      "200/200 [==============================] - 0s 778us/sample - loss: 0.2752 - accuracy: 0.9300 - val_loss: 0.2612 - val_accuracy: 0.9260\n",
      "Epoch 3/16\n",
      "200/200 [==============================] - 0s 780us/sample - loss: 0.2108 - accuracy: 0.9650 - val_loss: 0.2152 - val_accuracy: 0.9523\n",
      "Epoch 4/16\n",
      "200/200 [==============================] - 0s 780us/sample - loss: 0.1711 - accuracy: 0.9750 - val_loss: 0.1805 - val_accuracy: 0.9635\n",
      "Epoch 5/16\n",
      "200/200 [==============================] - 0s 785us/sample - loss: 0.1413 - accuracy: 0.9800 - val_loss: 0.1574 - val_accuracy: 0.9757\n",
      "Epoch 6/16\n",
      "200/200 [==============================] - 0s 761us/sample - loss: 0.1212 - accuracy: 0.9900 - val_loss: 0.1395 - val_accuracy: 0.9807\n",
      "Epoch 7/16\n",
      "200/200 [==============================] - 0s 764us/sample - loss: 0.1056 - accuracy: 0.9950 - val_loss: 0.1261 - val_accuracy: 0.9828\n",
      "Epoch 8/16\n",
      "200/200 [==============================] - 0s 771us/sample - loss: 0.0935 - accuracy: 1.0000 - val_loss: 0.1155 - val_accuracy: 0.9848\n",
      "Epoch 9/16\n",
      "200/200 [==============================] - 0s 809us/sample - loss: 0.0839 - accuracy: 1.0000 - val_loss: 0.1073 - val_accuracy: 0.9858\n",
      "Epoch 10/16\n",
      "200/200 [==============================] - 0s 866us/sample - loss: 0.0766 - accuracy: 1.0000 - val_loss: 0.1006 - val_accuracy: 0.9858\n",
      "Epoch 11/16\n",
      "200/200 [==============================] - 0s 919us/sample - loss: 0.0706 - accuracy: 1.0000 - val_loss: 0.0950 - val_accuracy: 0.9888\n",
      "Epoch 12/16\n",
      "200/200 [==============================] - 0s 841us/sample - loss: 0.0656 - accuracy: 1.0000 - val_loss: 0.0898 - val_accuracy: 0.9899\n",
      "Epoch 13/16\n",
      "200/200 [==============================] - 0s 818us/sample - loss: 0.0607 - accuracy: 1.0000 - val_loss: 0.0851 - val_accuracy: 0.9899\n",
      "Epoch 14/16\n",
      "200/200 [==============================] - 0s 843us/sample - loss: 0.0566 - accuracy: 1.0000 - val_loss: 0.0811 - val_accuracy: 0.9899\n",
      "Epoch 15/16\n",
      "200/200 [==============================] - 0s 835us/sample - loss: 0.0531 - accuracy: 1.0000 - val_loss: 0.0777 - val_accuracy: 0.9899\n",
      "Epoch 16/16\n",
      "200/200 [==============================] - 0s 795us/sample - loss: 0.0500 - accuracy: 1.0000 - val_loss: 0.0745 - val_accuracy: 0.9899\n"
     ]
    }
   ],
   "source": [
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = True # unfreeze\n",
    "\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\",\n",
    "                     optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                     metrics=[\"accuracy\"])\n",
    "\n",
    "# train more times\n",
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=16,\n",
    "                           validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, what's the final verdict?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1444666212797165, 0.9695]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B.evaluate(X_test_B, y_test_B, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.06899205100536346, 0.9925]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B_on_A.evaluate(X_test_B, y_test_B, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We got quite a bit of transfer: the error rate dropped by a factor of almost 4!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.066666666666663"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(100 - 96.95) / (100 - 99.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't get too excited yet! If you try to change the classes or the random seed, you will see that the improvement generally drops, or even vanishes or reverses. So take the effect with a grain of salt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faster Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Momentum optimization\n",
    "\n",
    "Momentum optimization cares a great deal about what previous gradients were: at each iteration, it subtracts the local gradient from the momentum vector $m$ (multiplied by the learning rate $\\eta$), and it updates the weights by simply adding this momentum vector.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "m \\leftarrow&  \\beta m + (1-\\beta) \\nabla_{\\theta}J(\\theta) \\\\\n",
    "\\theta \\leftarrow&  \\theta - \\eta m\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Typically, $\\beta\\ \\approx 0.9$ and it is considered $\\frac{1}{1-\\beta}$ days (instances) moving average. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nesterov Accelerated Gradient (NAG)\n",
    "\n",
    "NAG measures the gradient of the cost function not at the local position but __slightly ahead in the direction__ of the momentum. The only difference from vanilla Momentum optimization is that the gradient is measured at $\\theta + \\beta m$ rather than at $\\theta$.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "m \\leftarrow&  \\beta m + (1-\\beta) \\nabla_{\\theta}J(\\theta + \\beta m) \\\\\n",
    "\\theta \\leftarrow&  \\theta - \\eta m\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "This small tweak works because in general the momentum vector will be pointing in the right direction (i.e., toward the optimum), so it will be slightly more accurate to use the gradient measured a bit farther in that direction rather than using the gradient at the original position.\n",
    "\n",
    "![Figure 11-6](https://github.com/soo-pecialist/Hands_on_ML_w_Scikit_Karas_and_TensorFlow/blob/master/images_used/figure11_6.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(lr=0.001, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaGrad\n",
    "AdaGrad algorithm achieves going down the steepest slope by scaling down the gradient vector along the steepest dimensions. \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "s \\leftarrow&  s + \\nabla_{\\theta}J(\\theta) \\otimes \\nabla_{\\theta}J(\\theta) \\quad \\otimes \\text{is element-wise multiplication}\\\\\n",
    "\\theta \\leftarrow&  \\theta - \\eta \\nabla_{\\theta}J(\\theta) \\oslash \\sqrt{s + \\epsilon} \\quad \\oslash \\text{is element-wise division}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "In short, this algorithm decays the learning rate, but it does so faster for steep dimensions than for dimensions with gentler slopes. This is called an `adaptive learning rate`. It helps point the resulting updates more directly toward the global optimum.\n",
    "\n",
    "![Figure 11-7](https://github.com/soo-pecialist/Hands_on_ML_w_Scikit_Karas_and_TensorFlow/blob/master/images_used/figure11_7.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adagrad(lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`AdaGrad` often performs well for simple quadratic problems, but unfortunately it often stops too early when training neural networks. The learning rate gets scaled down so much that the algorithm ends up stopping entirely before reaching the global optimum. So even though Keras has an Adagrad optimizer, you __should not use it to train deep neural networks__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSProp\n",
    "Root Mean square propagation fixes AdaGrad problem by accumulating only the gradients form the most recent iterations (as opposed to all the gridents since the beginning of training).\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "s \\leftarrow&  \\beta s + (1-\\beta)\\nabla_{\\theta}J(\\theta) \\otimes \\nabla_{\\theta}J(\\theta) \\\\\n",
    "\\theta \\leftarrow&  \\theta - \\eta \\nabla_{\\theta}J(\\theta) \\oslash \\sqrt{s + \\epsilon}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Typically $\\beta \\approx 0.99$ or $0.9$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.RMSprop(lr=0.001, rho=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adam Optimization\n",
    "`Adaptive moment estimation` combines the ideas of `Momentum optimization` and `RMSProp`.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "m \\leftarrow& \\beta_1 m - (1-\\beta_1)\\nabla_{\\theta}J(\\theta) \\\\\n",
    "s \\leftarrow&  \\beta_2 s + (1-\\beta_2)\\nabla_{\\theta}J(\\theta) \\otimes \\nabla_{\\theta}J(\\theta) \\\\\n",
    "\\hat{m} \\leftarrow& \\frac{m}{1-\\beta_1^t} \\quad\\quad\\text{($t$ represents the # of iteration)}\\\\\n",
    "\\hat{s} \\leftarrow& \\frac{s}{1-\\beta_2^t} \\\\\n",
    "\\theta \\leftarrow&  \\theta - \\eta \\hat{m} \\oslash \\sqrt{\\hat{s} + \\epsilon} \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Typically, $\\beta_1 \\approx 0.9$ and $\\beta_2 \\approx 0.99 / 0.999$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adamax Optimization\n",
    "`Adam` just scales down the parameter updates by the square root of __s__. In short, Adam scales down the parameter updates by the $\\ell2$ norm of the time-decayed gradients (recall that the $\\ell2$ norm is the square root of the sum of squares). \n",
    "\n",
    "`Adamax` just replaces the $\\ell2$ norm with the $\\ell_{\\infty}$ norm (a fancy way of saying the max). Specifically, it replaces step 2 in `Adam` with \n",
    "$$\n",
    "s \\leftarrow \\max{(\\beta_2 s, \\nabla_{\\theta}J(\\theta)}\n",
    "$$\n",
    "it drops step 4, and in step 5 it scales down the gradient updates by a factor of s, which is just the max of the time-decayed gradients. \n",
    "\n",
    "In practice, this can make Adamax more stable than Adam, but this really depends on the dataset, and in general Adam actually performs better. So it’s just one more optimizer you can try if you experience problems with Adam on some task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adamax(lr=0.001, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nadam Optimization\n",
    "`Nadam` is more important: it is simply `Adam optimization` __plus__ the `Nesterov trick`, so it will often converge slightly faster than Adam. In his report, Timothy Dozat compares many different optimizers on various tasks, and finds that Nadam generally outperforms Adam, but is sometimes outperformed by `RMSProp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Nadam(lr=0.001, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> when you are disappointed by your model’s performance, try using plain Nesterov Accelerated Gradient instead: your dataset may just be allergic to adaptive gradients. Also check out the latest research, it is moving fast (e.g., AdaBound)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate Scheduling\n",
    "![Figure 11-8](https://github.com/soo-pecialist/Hands_on_ML_w_Scikit_Karas_and_TensorFlow/blob/master/images_used/figure11_8.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can do better than a constant learning rate: if you start with a high learning rate and then reduce it once it stops making fast progress, you can reach a good solution faster than with the optimal constant learning rate. There are many dif‐ ferent strategies to reduce the learning rate during training. These strategies are called `learning schedules`. Let's dive into most common approaches: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power Scheduling\n",
    "Set the learning rate to a function of the iteration number $t$:\n",
    "$$\n",
    "\\eta(t) = \\frac{\\eta_0}{(1 + t / s)^c} \\quad\\quad\\text{where,}\\hspace{0.1in} s = \\frac{1}{decay}\n",
    "$$\n",
    "\n",
    "This schedule first drops quickly, then more and more slowly. Of course, this requires tuning $\\eta_0, s$ (and possibly $c$).\n",
    "* Keras uses `c=1` and `s = 1 / decay`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decay` is included for backward compatibility to\n",
    "# allow time inverse decay of learning rate.\n",
    "optimizer = keras.optimizers.SGD(lr=0.01, decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "# we use optimizer here\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer, \n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/25\n",
      "55000/55000 [==============================] - 8s 145us/sample - loss: 0.4855 - accuracy: 0.8289 - val_loss: 0.4061 - val_accuracy: 0.8616\n",
      "Epoch 2/25\n",
      "55000/55000 [==============================] - 6s 108us/sample - loss: 0.3791 - accuracy: 0.8663 - val_loss: 0.3889 - val_accuracy: 0.8670\n",
      "Epoch 3/25\n",
      "55000/55000 [==============================] - 6s 102us/sample - loss: 0.3461 - accuracy: 0.8761 - val_loss: 0.3636 - val_accuracy: 0.8728\n",
      "Epoch 4/25\n",
      "55000/55000 [==============================] - 5s 89us/sample - loss: 0.3252 - accuracy: 0.8836 - val_loss: 0.3521 - val_accuracy: 0.8768\n",
      "Epoch 5/25\n",
      "55000/55000 [==============================] - 5s 88us/sample - loss: 0.3099 - accuracy: 0.8894 - val_loss: 0.3443 - val_accuracy: 0.8812\n",
      "Epoch 6/25\n",
      "55000/55000 [==============================] - 5s 91us/sample - loss: 0.2970 - accuracy: 0.8932 - val_loss: 0.3414 - val_accuracy: 0.8820\n",
      "Epoch 7/25\n",
      "55000/55000 [==============================] - 5s 87us/sample - loss: 0.2865 - accuracy: 0.8969 - val_loss: 0.3347 - val_accuracy: 0.8862\n",
      "Epoch 8/25\n",
      "55000/55000 [==============================] - 5s 86us/sample - loss: 0.2779 - accuracy: 0.9004 - val_loss: 0.3374 - val_accuracy: 0.8816\n",
      "Epoch 9/25\n",
      "55000/55000 [==============================] - 5s 90us/sample - loss: 0.2697 - accuracy: 0.9030 - val_loss: 0.3365 - val_accuracy: 0.8836\n",
      "Epoch 10/25\n",
      "55000/55000 [==============================] - 5s 95us/sample - loss: 0.2626 - accuracy: 0.9067 - val_loss: 0.3279 - val_accuracy: 0.8894\n",
      "Epoch 11/25\n",
      "55000/55000 [==============================] - 5s 99us/sample - loss: 0.2569 - accuracy: 0.9082 - val_loss: 0.3243 - val_accuracy: 0.8890\n",
      "Epoch 12/25\n",
      "55000/55000 [==============================] - 5s 99us/sample - loss: 0.2510 - accuracy: 0.9097 - val_loss: 0.3286 - val_accuracy: 0.8892\n",
      "Epoch 13/25\n",
      "55000/55000 [==============================] - 5s 99us/sample - loss: 0.2460 - accuracy: 0.9125 - val_loss: 0.3225 - val_accuracy: 0.8900\n",
      "Epoch 14/25\n",
      "55000/55000 [==============================] - 6s 104us/sample - loss: 0.2417 - accuracy: 0.9142 - val_loss: 0.3229 - val_accuracy: 0.8864\n",
      "Epoch 15/25\n",
      "55000/55000 [==============================] - 6s 101us/sample - loss: 0.2371 - accuracy: 0.9151 - val_loss: 0.3241 - val_accuracy: 0.8908\n",
      "Epoch 16/25\n",
      "55000/55000 [==============================] - 5s 96us/sample - loss: 0.2331 - accuracy: 0.9168 - val_loss: 0.3212 - val_accuracy: 0.8916\n",
      "Epoch 17/25\n",
      "55000/55000 [==============================] - 5s 96us/sample - loss: 0.2293 - accuracy: 0.9185 - val_loss: 0.3215 - val_accuracy: 0.8916\n",
      "Epoch 18/25\n",
      "55000/55000 [==============================] - 5s 99us/sample - loss: 0.2258 - accuracy: 0.9198 - val_loss: 0.3221 - val_accuracy: 0.8904\n",
      "Epoch 19/25\n",
      "55000/55000 [==============================] - 6s 101us/sample - loss: 0.2228 - accuracy: 0.9213 - val_loss: 0.3194 - val_accuracy: 0.8912\n",
      "Epoch 20/25\n",
      "55000/55000 [==============================] - 6s 106us/sample - loss: 0.2196 - accuracy: 0.9228 - val_loss: 0.3212 - val_accuracy: 0.8900\n",
      "Epoch 21/25\n",
      "55000/55000 [==============================] - 6s 110us/sample - loss: 0.2169 - accuracy: 0.9233 - val_loss: 0.3187 - val_accuracy: 0.8922\n",
      "Epoch 22/25\n",
      "55000/55000 [==============================] - 6s 112us/sample - loss: 0.2138 - accuracy: 0.9248 - val_loss: 0.3239 - val_accuracy: 0.8908\n",
      "Epoch 23/25\n",
      "55000/55000 [==============================] - 7s 118us/sample - loss: 0.2118 - accuracy: 0.9254 - val_loss: 0.3188 - val_accuracy: 0.8910\n",
      "Epoch 24/25\n",
      "55000/55000 [==============================] - 6s 118us/sample - loss: 0.2090 - accuracy: 0.9263 - val_loss: 0.3183 - val_accuracy: 0.8922\n",
      "Epoch 25/25\n",
      "55000/55000 [==============================] - 6s 118us/sample - loss: 0.2065 - accuracy: 0.9279 - val_loss: 0.3202 - val_accuracy: 0.8900\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 25\n",
    "# If unspecified, `batch_size` will default to 32.\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "decay = 1e-4\n",
    "batch_size = 32\n",
    "n_steps_per_epoch = len(X_train) // batch_size\n",
    "epochs = np.arange(n_epochs)\n",
    "lrs = learning_rate / (1 + decay * epochs * n_steps_per_epoch)\n",
    "\n",
    "plt.plot(epochs, lrs,  \"o-\")\n",
    "plt.axis([0, n_epochs - 1, 0, 0.01])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.title(\"Power Scheduling\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential Scheduling\n",
    "$$\n",
    "\\eta = \\eta_0 \\cdot 0.1^{\\frac{t}{s}}\n",
    "$$\n",
    "The learning rate will gradually drop by a factor of 10 every $s$ steps. While power scheduling reduces the learning rate more and more slowly, exponential scheduling keeps slashing it by a factor of 10 every $s$ steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we set n0 = 0.01, s = 20 as a default\n",
    "def exponential_decay_fn(epoch):\n",
    "    return 0.01 * 0.1**(epoch / 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do not want to hard-code $\\eta_0$ and $s$, you can create a function that returns a configured function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper function for `exponential_decay_fn()\n",
    "def exponential_decay(lr0, s):\n",
    "    def exponential_decay_fn(epoch):\n",
    "        return lr0 * 0.1**(epoch / s)\n",
    "    return exponential_decay_fn\n",
    "\n",
    "exponential_decay_fn = exponential_decay(lr0=0.01, s=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "              optimizer=\"nadam\", metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/25\n",
      "55000/55000 [==============================] - 12s 212us/sample - loss: 0.8791 - accuracy: 0.7481 - val_loss: 0.8047 - val_accuracy: 0.7612\n",
      "Epoch 2/25\n",
      "55000/55000 [==============================] - 9s 168us/sample - loss: 0.7890 - accuracy: 0.7654 - val_loss: 0.7888 - val_accuracy: 0.7766\n",
      "Epoch 3/25\n",
      "55000/55000 [==============================] - 8s 139us/sample - loss: 0.6607 - accuracy: 0.8023 - val_loss: 0.6255 - val_accuracy: 0.8314\n",
      "Epoch 4/25\n",
      "55000/55000 [==============================] - 6s 108us/sample - loss: 0.5977 - accuracy: 0.8262 - val_loss: 0.5678 - val_accuracy: 0.8278\n",
      "Epoch 5/25\n",
      "55000/55000 [==============================] - 5s 96us/sample - loss: 0.5283 - accuracy: 0.8465 - val_loss: 0.5615 - val_accuracy: 0.8504\n",
      "Epoch 6/25\n",
      "55000/55000 [==============================] - 5s 95us/sample - loss: 0.4725 - accuracy: 0.8591 - val_loss: 0.5955 - val_accuracy: 0.8574\n",
      "Epoch 7/25\n",
      "55000/55000 [==============================] - 5s 95us/sample - loss: 0.4337 - accuracy: 0.8699 - val_loss: 0.4793 - val_accuracy: 0.8592\n",
      "Epoch 8/25\n",
      "55000/55000 [==============================] - 5s 95us/sample - loss: 0.4105 - accuracy: 0.8769 - val_loss: 0.5221 - val_accuracy: 0.8618\n",
      "Epoch 9/25\n",
      "55000/55000 [==============================] - 5s 95us/sample - loss: 0.3749 - accuracy: 0.8865 - val_loss: 0.4892 - val_accuracy: 0.8694\n",
      "Epoch 10/25\n",
      "55000/55000 [==============================] - 5s 95us/sample - loss: 0.3462 - accuracy: 0.8919 - val_loss: 0.4281 - val_accuracy: 0.8790\n",
      "Epoch 11/25\n",
      "55000/55000 [==============================] - 5s 96us/sample - loss: 0.3227 - accuracy: 0.8988 - val_loss: 0.4480 - val_accuracy: 0.8802\n",
      "Epoch 12/25\n",
      "55000/55000 [==============================] - 6s 100us/sample - loss: 0.2950 - accuracy: 0.9041 - val_loss: 0.5224 - val_accuracy: 0.8612\n",
      "Epoch 13/25\n",
      "55000/55000 [==============================] - 6s 102us/sample - loss: 0.2644 - accuracy: 0.9107 - val_loss: 0.4997 - val_accuracy: 0.8784\n",
      "Epoch 14/25\n",
      "55000/55000 [==============================] - 6s 102us/sample - loss: 0.2509 - accuracy: 0.9157 - val_loss: 0.4469 - val_accuracy: 0.8848\n",
      "Epoch 15/25\n",
      "55000/55000 [==============================] - 6s 104us/sample - loss: 0.2296 - accuracy: 0.9217 - val_loss: 0.4363 - val_accuracy: 0.8832\n",
      "Epoch 16/25\n",
      "55000/55000 [==============================] - 6s 100us/sample - loss: 0.2164 - accuracy: 0.9268 - val_loss: 0.4495 - val_accuracy: 0.8866\n",
      "Epoch 17/25\n",
      "55000/55000 [==============================] - 6s 100us/sample - loss: 0.1988 - accuracy: 0.9315 - val_loss: 0.4806 - val_accuracy: 0.8746\n",
      "Epoch 18/25\n",
      "55000/55000 [==============================] - 5s 99us/sample - loss: 0.1833 - accuracy: 0.9350 - val_loss: 0.4706 - val_accuracy: 0.8932\n",
      "Epoch 19/25\n",
      "55000/55000 [==============================] - 6s 112us/sample - loss: 0.1732 - accuracy: 0.9391 - val_loss: 0.4819 - val_accuracy: 0.8840\n",
      "Epoch 20/25\n",
      "55000/55000 [==============================] - 7s 123us/sample - loss: 0.1609 - accuracy: 0.9424 - val_loss: 0.4681 - val_accuracy: 0.8852\n",
      "Epoch 21/25\n",
      "55000/55000 [==============================] - 8s 153us/sample - loss: 0.1478 - accuracy: 0.9477 - val_loss: 0.5036 - val_accuracy: 0.8854\n",
      "Epoch 22/25\n",
      "55000/55000 [==============================] - 9s 160us/sample - loss: 0.1383 - accuracy: 0.9503 - val_loss: 0.5208 - val_accuracy: 0.8906\n",
      "Epoch 23/25\n",
      "55000/55000 [==============================] - 9s 158us/sample - loss: 0.1302 - accuracy: 0.9535 - val_loss: 0.5557 - val_accuracy: 0.8862\n",
      "Epoch 24/25\n",
      "55000/55000 [==============================] - 8s 140us/sample - loss: 0.1211 - accuracy: 0.9569 - val_loss: 0.5540 - val_accuracy: 0.8898\n",
      "Epoch 25/25\n",
      "55000/55000 [==============================] - 7s 121us/sample - loss: 0.1132 - accuracy: 0.9599 - val_loss: 0.5767 - val_accuracy: 0.8934\n"
     ]
    }
   ],
   "source": [
    "# note that we use LearningRateScheduler()\n",
    "lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "n_epochs = 25\n",
    "\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.epoch, history.history[\"lr\"], \"o-\")\n",
    "plt.axis([0, n_epochs - 1, 0, 0.011])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.title(\"Exponential Scheduling\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The schedule function can take the current learning rate as a second argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay_fn(epoch, lr):\n",
    "    return lr * 0.1**(epoch / 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use `tf.keras` scheduler:\n",
    "```python\n",
    "s = 20 * len(X_train) // 32 # number of steps in 20 epochs (batch size = 32)\n",
    "learning_rate = keras.optimizers.schedules.ExponentialDecay(0.01, s, 0.1)\n",
    "optimizer = keras.optimizers.SGD(learning_rate)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to update the learning rate at each iteration rather than at each epoch, you must __write your own callback__ class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/25\n",
      "55000/55000 [==============================] - 8s 147us/sample - loss: 0.8203 - accuracy: 0.7638 - val_loss: 0.6589 - val_accuracy: 0.7478\n",
      "Epoch 2/25\n",
      "55000/55000 [==============================] - 7s 126us/sample - loss: 0.6001 - accuracy: 0.8137 - val_loss: 0.6194 - val_accuracy: 0.8252\n",
      "Epoch 3/25\n",
      "55000/55000 [==============================] - 7s 122us/sample - loss: 0.6239 - accuracy: 0.8127 - val_loss: 0.5372 - val_accuracy: 0.8466\n",
      "Epoch 4/25\n",
      "55000/55000 [==============================] - 7s 121us/sample - loss: 0.4856 - accuracy: 0.8479 - val_loss: 0.5099 - val_accuracy: 0.8584\n",
      "Epoch 5/25\n",
      "55000/55000 [==============================] - 6s 118us/sample - loss: 0.4700 - accuracy: 0.8540 - val_loss: 0.5246 - val_accuracy: 0.8640\n",
      "Epoch 6/25\n",
      "55000/55000 [==============================] - 7s 121us/sample - loss: 0.4119 - accuracy: 0.8694 - val_loss: 0.5124 - val_accuracy: 0.8432\n",
      "Epoch 7/25\n",
      "55000/55000 [==============================] - 7s 120us/sample - loss: 0.3877 - accuracy: 0.8750 - val_loss: 0.4663 - val_accuracy: 0.8586\n",
      "Epoch 8/25\n",
      "55000/55000 [==============================] - 7s 126us/sample - loss: 0.3646 - accuracy: 0.8823 - val_loss: 0.4739 - val_accuracy: 0.8584\n",
      "Epoch 9/25\n",
      "55000/55000 [==============================] - 8s 137us/sample - loss: 0.3305 - accuracy: 0.8912 - val_loss: 0.4748 - val_accuracy: 0.8626\n",
      "Epoch 10/25\n",
      "55000/55000 [==============================] - 8s 145us/sample - loss: 0.3065 - accuracy: 0.8990 - val_loss: 0.4242 - val_accuracy: 0.8798\n",
      "Epoch 11/25\n",
      "55000/55000 [==============================] - 8s 149us/sample - loss: 0.2868 - accuracy: 0.9039 - val_loss: 0.4212 - val_accuracy: 0.8828\n",
      "Epoch 12/25\n",
      "55000/55000 [==============================] - 8s 144us/sample - loss: 0.2577 - accuracy: 0.9130 - val_loss: 0.4488 - val_accuracy: 0.8932\n",
      "Epoch 13/25\n",
      "55000/55000 [==============================] - 8s 145us/sample - loss: 0.2459 - accuracy: 0.9184 - val_loss: 0.4406 - val_accuracy: 0.8910\n",
      "Epoch 14/25\n",
      "55000/55000 [==============================] - 8s 142us/sample - loss: 0.2301 - accuracy: 0.9229 - val_loss: 0.4167 - val_accuracy: 0.8880\n",
      "Epoch 15/25\n",
      "55000/55000 [==============================] - 8s 140us/sample - loss: 0.2076 - accuracy: 0.9298 - val_loss: 0.4348 - val_accuracy: 0.8894\n",
      "Epoch 16/25\n",
      "55000/55000 [==============================] - 7s 130us/sample - loss: 0.1945 - accuracy: 0.9338 - val_loss: 0.4582 - val_accuracy: 0.8886\n",
      "Epoch 17/25\n",
      "55000/55000 [==============================] - 7s 128us/sample - loss: 0.1792 - accuracy: 0.9396 - val_loss: 0.5349 - val_accuracy: 0.8846\n",
      "Epoch 18/25\n",
      "55000/55000 [==============================] - 7s 124us/sample - loss: 0.1695 - accuracy: 0.9436 - val_loss: 0.5087 - val_accuracy: 0.8856\n",
      "Epoch 19/25\n",
      "55000/55000 [==============================] - 7s 123us/sample - loss: 0.1545 - accuracy: 0.9483 - val_loss: 0.5506 - val_accuracy: 0.8878\n",
      "Epoch 20/25\n",
      "55000/55000 [==============================] - 7s 130us/sample - loss: 0.1436 - accuracy: 0.9527 - val_loss: 0.5442 - val_accuracy: 0.8856\n",
      "Epoch 21/25\n",
      "55000/55000 [==============================] - 8s 139us/sample - loss: 0.1344 - accuracy: 0.9554 - val_loss: 0.5640 - val_accuracy: 0.8906\n",
      "Epoch 22/25\n",
      "55000/55000 [==============================] - 8s 141us/sample - loss: 0.1243 - accuracy: 0.9597 - val_loss: 0.5614 - val_accuracy: 0.8920\n",
      "Epoch 23/25\n",
      "55000/55000 [==============================] - 8s 144us/sample - loss: 0.1152 - accuracy: 0.9631 - val_loss: 0.5777 - val_accuracy: 0.8932\n",
      "Epoch 24/25\n",
      "55000/55000 [==============================] - 8s 149us/sample - loss: 0.1055 - accuracy: 0.9665 - val_loss: 0.6132 - val_accuracy: 0.8898\n",
      "Epoch 25/25\n",
      "55000/55000 [==============================] - 8s 147us/sample - loss: 0.0984 - accuracy: 0.9691 - val_loss: 0.6288 - val_accuracy: 0.8946\n"
     ]
    }
   ],
   "source": [
    "K = keras.backend\n",
    "###\n",
    "class ExponentialDecay(keras.callbacks.Callback):\n",
    "    def __init__(self, s=40000):\n",
    "        super().__init__()\n",
    "        self.s = s\n",
    "\n",
    "    def on_batch_begin(self, batch, logs=None):\n",
    "        # Note: the `batch` argument is reset at each epoch\n",
    "        lr = K.get_value(self.model.optimizer.lr)\n",
    "        K.set_value(self.model.optimizer.lr, lr * 0.1**(1 / s))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        logs['lr'] = K.get_value(self.model.optimizer.lr)\n",
    "###\n",
    "        \n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "lr0 = 0.01\n",
    "optimizer = keras.optimizers.Nadam(lr=lr0)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "              optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "n_epochs = 25\n",
    "\n",
    "s = 20 * len(X_train) // 32 # number of steps in 20 epochs (batch size = 32)\n",
    "exp_decay = ExponentialDecay(s) #####\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[exp_decay])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = n_epochs * len(X_train) // 32\n",
    "steps = np.arange(n_steps)\n",
    "lrs = lr0 * 0.1**(steps / s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(steps, lrs, \"-\", linewidth=2)\n",
    "plt.axis([0, n_steps - 1, 0, lr0 * 1.1])\n",
    "plt.xlabel(\"Batch\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.title(\"Exponential Scheduling (per batch)\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Piecewise Constant Scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def piecewise_constant_fn(epoch):\n",
    "    if epoch < 5:\n",
    "        return 0.01\n",
    "    elif epoch < 15:\n",
    "        return 0.005\n",
    "    else:\n",
    "        return 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def piecewise_constant(boundaries, values):\n",
    "    boundaries = np.array([0] + boundaries)\n",
    "    values = np.array(values)\n",
    "    def piecewise_constant_fn(epoch):\n",
    "        return values[np.argmax(boundaries > epoch) - 1]\n",
    "    return piecewise_constant_fn\n",
    "\n",
    "piecewise_constant_fn = piecewise_constant([5, 15], [0.01, 0.005, 0.001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/25\n",
      "55000/55000 [==============================] - 8s 154us/sample - loss: 0.8467 - accuracy: 0.7548 - val_loss: 0.6916 - val_accuracy: 0.7870\n",
      "Epoch 2/25\n",
      "55000/55000 [==============================] - 7s 126us/sample - loss: 0.8773 - accuracy: 0.7448 - val_loss: 0.8764 - val_accuracy: 0.7300\n",
      "Epoch 3/25\n",
      "55000/55000 [==============================] - 7s 121us/sample - loss: 0.8141 - accuracy: 0.7514 - val_loss: 0.7061 - val_accuracy: 0.7926\n",
      "Epoch 4/25\n",
      "55000/55000 [==============================] - 6s 115us/sample - loss: 0.8484 - accuracy: 0.7474 - val_loss: 0.9703 - val_accuracy: 0.7018\n",
      "Epoch 5/25\n",
      "55000/55000 [==============================] - 6s 108us/sample - loss: 0.9469 - accuracy: 0.6942 - val_loss: 1.0555 - val_accuracy: 0.6986\n",
      "Epoch 6/25\n",
      "55000/55000 [==============================] - 6s 107us/sample - loss: 0.5998 - accuracy: 0.8128 - val_loss: 0.7847 - val_accuracy: 0.7972\n",
      "Epoch 7/25\n",
      "55000/55000 [==============================] - 6s 106us/sample - loss: 0.5386 - accuracy: 0.8350 - val_loss: 0.6020 - val_accuracy: 0.8464\n",
      "Epoch 8/25\n",
      "55000/55000 [==============================] - 6s 105us/sample - loss: 0.4893 - accuracy: 0.8468 - val_loss: 0.6093 - val_accuracy: 0.8404\n",
      "Epoch 9/25\n",
      "55000/55000 [==============================] - 6s 103us/sample - loss: 0.4853 - accuracy: 0.8515 - val_loss: 0.5770 - val_accuracy: 0.8468\n",
      "Epoch 10/25\n",
      "55000/55000 [==============================] - 6s 102us/sample - loss: 0.4698 - accuracy: 0.8547 - val_loss: 0.5969 - val_accuracy: 0.8584\n",
      "Epoch 11/25\n",
      "55000/55000 [==============================] - 6s 103us/sample - loss: 0.4659 - accuracy: 0.8561 - val_loss: 0.6385 - val_accuracy: 0.8558\n",
      "Epoch 12/25\n",
      "55000/55000 [==============================] - 6s 102us/sample - loss: 0.4352 - accuracy: 0.8651 - val_loss: 0.7114 - val_accuracy: 0.8188\n",
      "Epoch 13/25\n",
      "55000/55000 [==============================] - 6s 102us/sample - loss: 0.4232 - accuracy: 0.8674 - val_loss: 0.5894 - val_accuracy: 0.8512\n",
      "Epoch 14/25\n",
      "55000/55000 [==============================] - 6s 101us/sample - loss: 0.4389 - accuracy: 0.8699 - val_loss: 0.5885 - val_accuracy: 0.8554\n",
      "Epoch 15/25\n",
      "55000/55000 [==============================] - 5s 100us/sample - loss: 0.3898 - accuracy: 0.8735 - val_loss: 0.6640 - val_accuracy: 0.8384\n",
      "Epoch 16/25\n",
      "55000/55000 [==============================] - 5s 100us/sample - loss: 0.2705 - accuracy: 0.9060 - val_loss: 0.5165 - val_accuracy: 0.8812\n",
      "Epoch 17/25\n",
      "55000/55000 [==============================] - 6s 101us/sample - loss: 0.2408 - accuracy: 0.9155 - val_loss: 0.5336 - val_accuracy: 0.8756\n",
      "Epoch 18/25\n",
      "55000/55000 [==============================] - 6s 113us/sample - loss: 0.2277 - accuracy: 0.9177 - val_loss: 0.5122 - val_accuracy: 0.8794\n",
      "Epoch 19/25\n",
      "55000/55000 [==============================] - 7s 121us/sample - loss: 0.2153 - accuracy: 0.9220 - val_loss: 0.5548 - val_accuracy: 0.8800\n",
      "Epoch 20/25\n",
      "55000/55000 [==============================] - 7s 127us/sample - loss: 0.2075 - accuracy: 0.9258 - val_loss: 0.5192 - val_accuracy: 0.8788\n",
      "Epoch 21/25\n",
      "55000/55000 [==============================] - 7s 132us/sample - loss: 0.1958 - accuracy: 0.9301 - val_loss: 0.5624 - val_accuracy: 0.8826\n",
      "Epoch 22/25\n",
      "55000/55000 [==============================] - 7s 132us/sample - loss: 0.1891 - accuracy: 0.9324 - val_loss: 0.5780 - val_accuracy: 0.8816\n",
      "Epoch 23/25\n",
      "55000/55000 [==============================] - 7s 132us/sample - loss: 0.1799 - accuracy: 0.9357 - val_loss: 0.5986 - val_accuracy: 0.8812\n",
      "Epoch 24/25\n",
      "55000/55000 [==============================] - 7s 134us/sample - loss: 0.1735 - accuracy: 0.9380 - val_loss: 0.5872 - val_accuracy: 0.8832\n",
      "Epoch 25/25\n",
      "55000/55000 [==============================] - 7s 126us/sample - loss: 0.1657 - accuracy: 0.9410 - val_loss: 0.6078 - val_accuracy: 0.8788\n"
     ]
    }
   ],
   "source": [
    "lr_scheduler = keras.callbacks.LearningRateScheduler(piecewise_constant_fn)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 25\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.epoch, [piecewise_constant_fn(epoch) for epoch in history.epoch], \"o-\")\n",
    "plt.axis([0, n_epochs - 1, 0, 0.011])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.title(\"Piecewise Constant Scheduling\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use `tf.keras` scheduler try this:\n",
    "```python\n",
    "learning_rate = keras.optimizers.schedules.PiecewiseConstantDecay(\n",
    "    boundaries=[5. * n_steps_per_epoch, 15. * n_steps_per_epoch],\n",
    "    values=[0.01, 0.005, 0.001])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Scheduling\n",
    "Measure the validation error every $N$ steps (just like for early stopping) and reduce the learning rate by a factor of $\\lambda$ when the error stops dropping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply use the `ReduceLROnPlateau` callback. For exam‐ ple, if you pass the following callback to the fit() method, it will multiply the learning rate by 0.5 whenever the best validation loss does not improve for 5 consecutive epochs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/25\n",
      "55000/55000 [==============================] - 5s 92us/sample - loss: 0.6036 - accuracy: 0.8052 - val_loss: 0.5546 - val_accuracy: 0.8126\n",
      "Epoch 2/25\n",
      "55000/55000 [==============================] - 4s 81us/sample - loss: 0.5147 - accuracy: 0.8370 - val_loss: 0.5252 - val_accuracy: 0.8346\n",
      "Epoch 3/25\n",
      "55000/55000 [==============================] - 4s 74us/sample - loss: 0.5197 - accuracy: 0.8430 - val_loss: 0.4358 - val_accuracy: 0.8590\n",
      "Epoch 4/25\n",
      "55000/55000 [==============================] - 4s 74us/sample - loss: 0.5022 - accuracy: 0.8494 - val_loss: 0.5276 - val_accuracy: 0.8514\n",
      "Epoch 5/25\n",
      "55000/55000 [==============================] - 4s 71us/sample - loss: 0.5252 - accuracy: 0.8486 - val_loss: 0.5415 - val_accuracy: 0.8492\n",
      "Epoch 6/25\n",
      "55000/55000 [==============================] - 4s 72us/sample - loss: 0.4994 - accuracy: 0.8563 - val_loss: 0.7048 - val_accuracy: 0.8370\n",
      "Epoch 7/25\n",
      "55000/55000 [==============================] - 4s 73us/sample - loss: 0.5450 - accuracy: 0.8497 - val_loss: 0.6937 - val_accuracy: 0.8242\n",
      "Epoch 8/25\n",
      "55000/55000 [==============================] - 4s 72us/sample - loss: 0.5433 - accuracy: 0.8527 - val_loss: 0.8240 - val_accuracy: 0.8108\n",
      "Epoch 9/25\n",
      "55000/55000 [==============================] - 4s 67us/sample - loss: 0.3026 - accuracy: 0.8954 - val_loss: 0.4257 - val_accuracy: 0.8656\n",
      "Epoch 10/25\n",
      "55000/55000 [==============================] - 4s 68us/sample - loss: 0.2475 - accuracy: 0.9094 - val_loss: 0.3844 - val_accuracy: 0.8804\n",
      "Epoch 11/25\n",
      "55000/55000 [==============================] - 4s 65us/sample - loss: 0.2347 - accuracy: 0.9148 - val_loss: 0.4192 - val_accuracy: 0.8822\n",
      "Epoch 12/25\n",
      "55000/55000 [==============================] - 3s 61us/sample - loss: 0.2173 - accuracy: 0.9211 - val_loss: 0.3936 - val_accuracy: 0.8924\n",
      "Epoch 13/25\n",
      "55000/55000 [==============================] - 3s 60us/sample - loss: 0.2014 - accuracy: 0.9251 - val_loss: 0.4320 - val_accuracy: 0.8888\n",
      "Epoch 14/25\n",
      "55000/55000 [==============================] - 3s 57us/sample - loss: 0.1868 - accuracy: 0.9288 - val_loss: 0.5198 - val_accuracy: 0.8716\n",
      "Epoch 15/25\n",
      "55000/55000 [==============================] - 3s 59us/sample - loss: 0.1815 - accuracy: 0.9318 - val_loss: 0.4840 - val_accuracy: 0.8838\n",
      "Epoch 16/25\n",
      "55000/55000 [==============================] - 3s 59us/sample - loss: 0.1284 - accuracy: 0.9496 - val_loss: 0.4411 - val_accuracy: 0.8946\n",
      "Epoch 17/25\n",
      "55000/55000 [==============================] - 3s 56us/sample - loss: 0.1142 - accuracy: 0.9553 - val_loss: 0.4634 - val_accuracy: 0.8900\n",
      "Epoch 18/25\n",
      "55000/55000 [==============================] - 3s 58us/sample - loss: 0.1054 - accuracy: 0.9582 - val_loss: 0.4877 - val_accuracy: 0.8900\n",
      "Epoch 19/25\n",
      "55000/55000 [==============================] - 3s 63us/sample - loss: 0.0995 - accuracy: 0.9611 - val_loss: 0.4922 - val_accuracy: 0.8922\n",
      "Epoch 20/25\n",
      "55000/55000 [==============================] - 3s 63us/sample - loss: 0.0951 - accuracy: 0.9631 - val_loss: 0.4964 - val_accuracy: 0.8866\n",
      "Epoch 21/25\n",
      "55000/55000 [==============================] - 4s 68us/sample - loss: 0.0733 - accuracy: 0.9723 - val_loss: 0.5147 - val_accuracy: 0.8918\n",
      "Epoch 22/25\n",
      "55000/55000 [==============================] - 4s 70us/sample - loss: 0.0686 - accuracy: 0.9740 - val_loss: 0.5208 - val_accuracy: 0.8948\n",
      "Epoch 23/25\n",
      "55000/55000 [==============================] - 4s 70us/sample - loss: 0.0648 - accuracy: 0.9757 - val_loss: 0.5321 - val_accuracy: 0.8930\n",
      "Epoch 24/25\n",
      "55000/55000 [==============================] - 4s 71us/sample - loss: 0.0619 - accuracy: 0.9773 - val_loss: 0.5434 - val_accuracy: 0.8934\n",
      "Epoch 25/25\n",
      "55000/55000 [==============================] - 4s 67us/sample - loss: 0.0579 - accuracy: 0.9787 - val_loss: 0.5525 - val_accuracy: 0.8962\n"
     ]
    }
   ],
   "source": [
    "lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "optimizer = keras.optimizers.SGD(lr=0.02, momentum=0.9)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "              optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "n_epochs = 25\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.epoch, history.history[\"lr\"], \"bo-\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Learning Rate\", color='b')\n",
    "plt.tick_params('y', colors='b')\n",
    "plt.gca().set_xlim(0, n_epochs - 1)\n",
    "plt.grid(True)\n",
    "\n",
    "ax2 = plt.gca().twinx()\n",
    "ax2.plot(history.epoch, history.history[\"val_loss\"], \"r^-\")\n",
    "ax2.set_ylabel('Validation Loss', color='r')\n",
    "ax2.tick_params('y', colors='r')\n",
    "\n",
    "plt.title(\"Reduce LR on Plateau\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avoiding Overfitting Through Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\ell_1$ and $\\ell_2$ regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(100, activation=\"elu\",\n",
    "                           kernel_initializer=\"he_normal\",\n",
    "                           kernel_regularizer=keras.regularizers.l2(0.01)) # here l2\n",
    "# or l1(0.1) for ℓ1 regularization with a factor or 0.1\n",
    "# or l1_l2(0.1, 0.01) for both ℓ1 and ℓ2 regularization, with factors 0.1 and 0.01 respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/2\n",
      "55000/55000 [==============================] - 7s 124us/sample - loss: 1.5895 - accuracy: 0.8103 - val_loss: 0.7553 - val_accuracy: 0.8096\n",
      "Epoch 2/2\n",
      "55000/55000 [==============================] - 6s 111us/sample - loss: 0.7184 - accuracy: 0.8264 - val_loss: 0.7178 - val_accuracy: 0.8222\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"elu\",\n",
    "                       kernel_initializer=\"he_normal\",\n",
    "                       kernel_regularizer=keras.regularizers.l2(0.01)), #\n",
    "    keras.layers.Dense(100, activation=\"elu\",\n",
    "                       kernel_initializer=\"he_normal\",\n",
    "                       kernel_regularizer=keras.regularizers.l2(0.01)), #\n",
    "    keras.layers.Dense(10, activation=\"softmax\",\n",
    "                       kernel_regularizer=keras.regularizers.l2(0.01)) #\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "              optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 2\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since you will typically want to apply the same regularizer to all layers in your network, as well as the same activation function and the same initialization strategy in all hidden layers, you may find yourself repeating the same arguments over and over. This makes it ugly and error-prone. To avoid this, you can try refactoring your code to use loops. Another option is to use Python’s `functools.partial()` function: it lets you create a thin wrapper for any callable, with some default argument values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/2\n",
      "55000/55000 [==============================] - 7s 123us/sample - loss: 1.6418 - accuracy: 0.8107 - val_loss: 0.7600 - val_accuracy: 0.8068\n",
      "Epoch 2/2\n",
      "55000/55000 [==============================] - 6s 105us/sample - loss: 0.7197 - accuracy: 0.8262 - val_loss: 0.7175 - val_accuracy: 0.8254\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "RegularizedDense = partial(keras.layers.Dense,\n",
    "                           activation=\"elu\",\n",
    "                           kernel_initializer=\"he_normal\",\n",
    "                           kernel_regularizer=keras.regularizers.l2(0.01))\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    RegularizedDense(300), #\n",
    "    RegularizedDense(100), #\n",
    "    RegularizedDense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 2\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a fairly simple algorithm: at every training step, every neuron (including the input neurons, but always excluding the output neurons) has a probability $p$ of being temporarily “dropped out,” meaning it will be entirely ignored during this training step, but it may be active during the next step. The hyperparameter $p$ is called the dropout rate, and it is typically set to 50%. After training, neurons don’t get dropped anymore. \n",
    "\n",
    "![Figure 11-9](https://github.com/soo-pecialist/Hands_on_ML_w_Scikit_Karas_and_TensorFlow/blob/master/images_used/figure11-9.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/2\n",
      "55000/55000 [==============================] - 7s 121us/sample - loss: 0.5765 - accuracy: 0.8004 - val_loss: 0.3741 - val_accuracy: 0.8642\n",
      "Epoch 2/2\n",
      "55000/55000 [==============================] - 6s 109us/sample - loss: 0.4243 - accuracy: 0.8441 - val_loss: 0.3647 - val_accuracy: 0.8612\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 2\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Since dropout is only active during training, the training loss is penalized compared to the validation loss, so comparing the two can be misleading. In particular, a model may be overfitting the training set and yet have similar training and validation losses. So make sure to evaluate the training loss without dropout (e.g., after training). Alternatively, you can call the `fit()` method inside a `with keras.backend.learning_phase_scope(1)` block: this will force dropout to be active during both training and validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 2\n",
    "\n",
    "## note here\n",
    "with keras.backend.learning_phase_scope(1):\n",
    "    history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                        validation_data=(X_valid_scaled, y_valid))\n",
    "```\n",
    "\n",
    "If you observe that the model is overfitting, you can increase the dropout rate. Conversely, you should try decreasing the dropout rate if the model underfits the training set. It can also help to increase the dropout rate for large layers, and reduce it for small ones. Moreover, many state-of-the-art architectures only use dropout after the last hidden layer, so you may want to try this if full dropout is too strong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alpha Dropout\n",
    "\n",
    "If you want to regularize a __self-normalizing__ network based on the `SELU activation` function, you should use` AlphaDropou`: this is a variant of dropout that __preserves the mean and standard deviation of its inputs__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "55000/55000 [==============================] - 4s 82us/sample - loss: 0.6659 - accuracy: 0.7579 - val_loss: 0.6300 - val_accuracy: 0.8340\n",
      "Epoch 2/20\n",
      "55000/55000 [==============================] - 4s 76us/sample - loss: 0.5578 - accuracy: 0.7953 - val_loss: 0.5326 - val_accuracy: 0.8478\n",
      "Epoch 3/20\n",
      "55000/55000 [==============================] - 4s 75us/sample - loss: 0.5243 - accuracy: 0.8074 - val_loss: 0.5626 - val_accuracy: 0.8538\n",
      "Epoch 4/20\n",
      "55000/55000 [==============================] - 4s 76us/sample - loss: 0.5069 - accuracy: 0.8132 - val_loss: 0.5007 - val_accuracy: 0.8554\n",
      "Epoch 5/20\n",
      "55000/55000 [==============================] - 4s 79us/sample - loss: 0.4936 - accuracy: 0.8162 - val_loss: 0.5082 - val_accuracy: 0.8546\n",
      "Epoch 6/20\n",
      "55000/55000 [==============================] - 5s 86us/sample - loss: 0.4816 - accuracy: 0.8212 - val_loss: 0.4956 - val_accuracy: 0.8640\n",
      "Epoch 7/20\n",
      "55000/55000 [==============================] - 5s 88us/sample - loss: 0.4706 - accuracy: 0.8234 - val_loss: 0.5139 - val_accuracy: 0.8588\n",
      "Epoch 8/20\n",
      "55000/55000 [==============================] - 5s 87us/sample - loss: 0.4680 - accuracy: 0.8278 - val_loss: 0.4804 - val_accuracy: 0.8598\n",
      "Epoch 9/20\n",
      "55000/55000 [==============================] - 5s 87us/sample - loss: 0.4610 - accuracy: 0.8287 - val_loss: 0.4866 - val_accuracy: 0.8564\n",
      "Epoch 10/20\n",
      "55000/55000 [==============================] - 5s 83us/sample - loss: 0.4512 - accuracy: 0.8318 - val_loss: 0.4352 - val_accuracy: 0.8674\n",
      "Epoch 11/20\n",
      "55000/55000 [==============================] - 4s 81us/sample - loss: 0.4473 - accuracy: 0.8345 - val_loss: 0.4809 - val_accuracy: 0.8626\n",
      "Epoch 12/20\n",
      "55000/55000 [==============================] - 4s 75us/sample - loss: 0.4409 - accuracy: 0.8368 - val_loss: 0.4775 - val_accuracy: 0.8646\n",
      "Epoch 13/20\n",
      "55000/55000 [==============================] - 4s 77us/sample - loss: 0.4444 - accuracy: 0.8342 - val_loss: 0.4366 - val_accuracy: 0.8682\n",
      "Epoch 14/20\n",
      "55000/55000 [==============================] - 4s 77us/sample - loss: 0.4344 - accuracy: 0.8386 - val_loss: 0.4156 - val_accuracy: 0.8742\n",
      "Epoch 15/20\n",
      "55000/55000 [==============================] - 4s 77us/sample - loss: 0.4362 - accuracy: 0.8387 - val_loss: 0.4256 - val_accuracy: 0.8746\n",
      "Epoch 16/20\n",
      "55000/55000 [==============================] - 4s 77us/sample - loss: 0.4302 - accuracy: 0.8403 - val_loss: 0.4852 - val_accuracy: 0.8640\n",
      "Epoch 17/20\n",
      "55000/55000 [==============================] - 4s 77us/sample - loss: 0.4257 - accuracy: 0.8411 - val_loss: 0.5288 - val_accuracy: 0.8656\n",
      "Epoch 18/20\n",
      "55000/55000 [==============================] - 4s 74us/sample - loss: 0.4224 - accuracy: 0.8412 - val_loss: 0.4465 - val_accuracy: 0.8728\n",
      "Epoch 19/20\n",
      "55000/55000 [==============================] - 4s 75us/sample - loss: 0.4242 - accuracy: 0.8433 - val_loss: 0.5024 - val_accuracy: 0.8686\n",
      "Epoch 20/20\n",
      "55000/55000 [==============================] - 4s 75us/sample - loss: 0.4220 - accuracy: 0.8419 - val_loss: 0.3997 - val_accuracy: 0.8754\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.AlphaDropout(rate=0.2),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.AlphaDropout(rate=0.2),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.AlphaDropout(rate=0.2),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "optimizer = keras.optimizers.SGD(lr=0.01, momentum=0.9, nesterov=True)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "              optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "n_epochs = 20\n",
    "with keras.backend.learning_phase_scope(1):\n",
    "    history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                        validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.44200247914493085, 0.8656]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_scaled, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.31944636237133633, 0.8884]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train_scaled, y_train, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples\n",
      "55000/55000 [==============================] - 4s 73us/sample - loss: 0.4174 - accuracy: 0.8433\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte-Carlo (MC) Dropout\n",
    "In 2016, a paper by Yarin Gal and Zoubin Ghahramani added more good reasons to use dropout:\n",
    "- First, the paper establishes a profound connection between dropout networks (i.e., neural networks containing a dropout layer before every weight layer) and approximate Bayesian inference, giving dropout a solid mathematical justification.\n",
    "- Second, they introduce a powerful technique called MC Dropout, which can boost the performance of any trained dropout model, without having to retrain it or even modify it at all!\n",
    "- Moreover, MC Dropout also provides a much better measure of the model’s uncertainty.\n",
    "- Finally, it is also amazingly simple to implement. If this all sounds like a “one weird trick” advertisement, then take a look at the following code. It is the full implementation of MC Dropout, boosting the dropout model we trained earlier, without retraining it:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer flatten_17 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with keras.backend.learning_phase_scope(1): # force training mode = dropout on\n",
    "    y_probas = np.stack([model(X_test_scaled, training=True) \n",
    "                         for sample in range(100)])\n",
    "y_proba = y_probas.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.35492177e-23, 7.81109961e-18, 3.00895909e-23, 1.06890016e-20,\n",
       "        3.40067208e-24, 1.42814254e-03, 3.83531923e-27, 3.24390782e-03,\n",
       "        4.86024527e-18, 9.95327950e-01]], dtype=float32)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test_scaled[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(model.predict(X_test_scaled[:1]), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.49, 0.  , 0.45]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.97, 0.  , 0.03]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.94, 0.  , 0.  , 0.  , 0.06]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.21, 0.  , 0.76]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.07, 0.  , 0.91]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.46, 0.  , 0.5 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.52, 0.  , 0.23, 0.  , 0.25]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.37, 0.  , 0.59]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.97, 0.  , 0.  , 0.  , 0.02]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.06, 0.  , 0.02, 0.  , 0.92]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.5 , 0.  , 0.5 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.21, 0.  , 0.01, 0.  , 0.78]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.86, 0.  , 0.08, 0.  , 0.05]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.17, 0.  , 0.79]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.48, 0.  , 0.15, 0.  , 0.37]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.55, 0.  , 0.01, 0.  , 0.44]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.25, 0.  , 0.  , 0.  , 0.75]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.06, 0.  , 0.52, 0.  , 0.42]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.71, 0.  , 0.28]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.13, 0.  , 0.28, 0.  , 0.58]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.28, 0.  , 0.71]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.78, 0.  , 0.14, 0.  , 0.08]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.03, 0.  , 0.93]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.14, 0.  , 0.86]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.19, 0.  , 0.76]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.44, 0.  , 0.55]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.13, 0.  , 0.82]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.66, 0.  , 0.05, 0.  , 0.29]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.24, 0.  , 0.03, 0.  , 0.74]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.23, 0.  , 0.59, 0.  , 0.18]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.28, 0.  , 0.69]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.02, 0.  , 0.93]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.48, 0.  , 0.04, 0.  , 0.48]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.07, 0.  , 0.9 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.24, 0.  , 0.64, 0.  , 0.12]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.28, 0.  , 0.01, 0.  , 0.71]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.33, 0.  , 0.08, 0.  , 0.59]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.27, 0.  , 0.06, 0.  , 0.67]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.35, 0.  , 0.  , 0.  , 0.64]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.16, 0.  , 0.1 , 0.  , 0.74]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.02, 0.  , 0.97]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.92, 0.  , 0.  , 0.  , 0.08]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.98]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.39, 0.  , 0.56]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.08, 0.  , 0.91]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.02, 0.  , 0.97]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.11, 0.  , 0.89]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.12, 0.  , 0.17, 0.  , 0.71]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.73, 0.  , 0.09, 0.  , 0.18]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.15, 0.  , 0.51, 0.  , 0.34]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.9 , 0.  , 0.01, 0.  , 0.1 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.89, 0.  , 0.  , 0.  , 0.11]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.03, 0.  , 0.96]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.96]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.08, 0.  , 0.55, 0.  , 0.37]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.48, 0.  , 0.29, 0.  , 0.23]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.07, 0.  , 0.91]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.22, 0.  , 0.02, 0.  , 0.76]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.1 , 0.  , 0.9 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.03, 0.  , 0.93]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.47, 0.  , 0.49]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.12, 0.  , 0.01, 0.  , 0.88]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.32, 0.  , 0.42, 0.  , 0.25]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.39, 0.  , 0.53, 0.  , 0.08]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.08, 0.  , 0.91]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.02, 0.  , 0.98]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.03, 0.  , 0.95]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.96]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.06, 0.  , 0.93]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.23, 0.  , 0.04, 0.  , 0.73]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.98]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.02, 0.  , 0.95]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.08, 0.  , 0.1 , 0.  , 0.82]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.72, 0.  , 0.24]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.96]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.15, 0.  , 0.78]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.36, 0.  , 0.05, 0.  , 0.59]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.05, 0.  , 0.9 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.01, 0.  , 0.96]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.12, 0.  , 0.88]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.31, 0.  , 0.66]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.5 , 0.  , 0.21, 0.  , 0.29]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.89, 0.  , 0.11, 0.  , 0.  ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.06, 0.  , 0.01, 0.  , 0.92]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.16, 0.  , 0.83]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.11, 0.  , 0.89]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.54, 0.  , 0.24, 0.  , 0.22]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.95]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.41, 0.  , 0.56, 0.  , 0.04]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.08, 0.  , 0.85]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.01, 0.  , 0.97]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.08, 0.  , 0.9 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.42, 0.  , 0.09, 0.  , 0.48]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.13, 0.  , 0.09, 0.  , 0.78]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.87, 0.  , 0.01, 0.  , 0.12]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.97, 0.  , 0.02, 0.  , 0.01]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(y_probas[:, :1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.21, 0.  , 0.16, 0.  , 0.63]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(y_proba[:1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.29, 0.  , 0.2 , 0.  , 0.32]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_std = y_probas.std(axis=0)\n",
    "np.round(y_std[:1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(y_proba, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.869"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = np.sum(y_pred == y_test) / len(y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The number of Monte Carlo samples you use (100 in this example) is a hyperparameter you can tweak. The higher it is, the more accurate the predictions and their uncertainty estimates will be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your model contains other layers that behave in a special way during training (such as Batch Normalization layers), then you __should not force training mode__ like we just did. Instead, you should __replace the Dropout layers with the following__ `MCDropout` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCDropout(keras.layers.Dropout):\n",
    "    def call(self, inputs):\n",
    "        return super().call(inputs, training=True) # only force training on dropout layer\n",
    "\n",
    "class MCAlphaDropout(keras.layers.AlphaDropout):\n",
    "    def call(self, inputs):\n",
    "        return super().call(inputs, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy layers\n",
    "mc_model = keras.models.Sequential([\n",
    "    MCAlphaDropout(layer.rate) if isinstance(layer, keras.layers.AlphaDropout) else layer\n",
    "    for layer in model.layers\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_17 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "mc_alpha_dropout (MCAlphaDro (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_259 (Dense)            (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "mc_alpha_dropout_1 (MCAlphaD (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_260 (Dense)            (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "mc_alpha_dropout_2 (MCAlphaD (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_261 (Dense)            (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mc_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(lr=0.01, momentum=0.9, nesterov=True)\n",
    "mc_model.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "                 optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy weights\n",
    "mc_model.set_weights(model.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the model with MC Dropout:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.23, 0.  , 0.2 , 0.  , 0.57]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(np.mean([mc_model.predict(X_test_scaled[:1]) \n",
    "                  for sample in range(100)], axis=0), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max norm\n",
    "Max-norm regularization does not add a regularization loss term to the overall loss function. Instead, it is typically implemented by computing ∥w∥2 after each training\n",
    "step and clipping $w$ if needed ($w \\leftarrow w\\frac{r}{\\lVert w \\rVert_2}$)\n",
    "Reducing $r$ increases the amount of regularization and helps reduce overfitting. Max-norm regularization can also help alleviate the vanishing/exploding gradients problems (if you are not using Batch Normalization). Here $r$ is the max-norm hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                           kernel_constraint=keras.constraints.max_norm(1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/2\n",
      "55000/55000 [==============================] - 7s 122us/sample - loss: 0.4762 - accuracy: 0.8327 - val_loss: 0.3840 - val_accuracy: 0.8648\n",
      "Epoch 2/2\n",
      "55000/55000 [==============================] - 7s 122us/sample - loss: 0.3597 - accuracy: 0.8685 - val_loss: 0.3604 - val_accuracy: 0.8682\n"
     ]
    }
   ],
   "source": [
    "MaxNormDense = partial(keras.layers.Dense,\n",
    "                       activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       kernel_constraint=keras.constraints.max_norm(1.))\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    MaxNormDense(300),\n",
    "    MaxNormDense(100),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 2\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "We have covered a wide range of techniques and you may be wondering which ones you should use. The configuration in the table below will work fine in most cases, without requiring much hyperparameter tuning.\n",
    "\n",
    "<img src=\"https://github.com/soo-pecialist/Hands_on_ML_w_Scikit_Karas_and_TensorFlow/blob/master/images_used/table11-2.png?raw=true\" width=300>\n",
    "\n",
    "The default configuration may need to be tweaked:\n",
    "- If your model self-normalizes:\n",
    "    * If it overfits the training set, then you should add alpha dropout (and always use early stopping as well). Do not use other regularization methods, or else they would break self-normalization.\n",
    "- If your model cannot self-normalize (e.g., it is a recurrent net or it contains skip connections):\n",
    "    * You can try using `ELU` (or another activation function) instead of SELU, it may perform better. Make sure to change the initialization method accordingly (e.g., `He` init for `ELU` or `ReLU`).\n",
    "    * If it is a deep network, you should use Batch Normalization after every hidden layer. If it overfits the training set, you can also try using max-norm or $\\ell2$ regularization.\n",
    "- If you need a sparse model, you can use $\\ell1$ regularization (and optionally zero out the tiny weights after training). If you need an even sparser model, you can try using `FTRL` instead of `Nadam` optimization, along with $\\ell1$ regularization. In any case, this will break self-normalization, so you will need to switch to `BN` if your model is deep.\n",
    "- If you need a low-latency model (one that performs lightning-fast predictions), you may need to use less layers, avoid Batch Normalization, and possibly replace the `SELU` activation function with the leaky ReLU. Having a sparse model will also help. You may also want to reduce the float precision from 32-bits to 16-bit (or even 8-bits).\n",
    "- If you are building a risk-sensitive application, or inference latency is not very important in your application, you can use `MC Dropout` to boost performance and get more reliable probability estimates, along with uncertainty estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
